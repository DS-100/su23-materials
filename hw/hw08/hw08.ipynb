{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9567f68f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw08.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7303b644",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"top\"></a>\n",
    "\n",
    "# Homework 8: SQL + PCA\n",
    "\n",
    "We will use SQL to dive deep into the Internet Movie Database (IMDb) and answer different questions involving movies, actors, and movie ratings.\n",
    "## Due Date: Monday, August 7th, 11:59 PM PDT\n",
    "\n",
    "You must submit this assignment to Gradescope by the on-time deadline, Monday, August 7th at 11:59pm. Please read the syllabus for the grace period policy. No late submissions beyond the grace period will be accepted. **We strongly encourage you to plan to submit your work to Gradescope several hours before the stated deadline.** This way, you will have ample time to reach out to staff for support if you encounter difficulties with submission. While course staff is happy to help guide you with submitting your assignment ahead of the deadline, we will not respond to last-minute requests for assistance (TAs need to sleep, after all!).\n",
    "\n",
    "Please read the instructions carefully to submit your work to both the coding and written portals of Gradescope.\n",
    "\n",
    "\n",
    "##  Collaboration Policy\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about\n",
    "the homework, we ask that you **write your solutions individually**. If you do\n",
    "discuss the assignments with others please **include their names** below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aca732",
   "metadata": {},
   "source": [
    "**Collaborators**: *list collaborators here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc732a3c",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This homework has two disjoint parts:\n",
    "\n",
    "**Part 1:** We will use SQL to dive deep into the Internet Movie Database (IMDb) and answer different questions involving movies, actors, and movie ratings. [Click here to jump to Part 1](#part-1).\n",
    "\n",
    "**Part 2:** We will use Principal Component Analysis to understand a high-dimensional dataset: U.S. Presidential Elections by State. [Click here to jump to Part 2](#part-2).\n",
    "\n",
    "## Grading \n",
    "\n",
    "Grading is broken down into autograded answers and free response. For autograded answers, the results of your code are compared to provided and/or hidden tests. For free response, readers will evaluate how well you answered the question and/or fulfilled the requirements of the question.\n",
    "\n",
    "<!--\n",
    "<details>\n",
    "    <summary>[Click to Expand] <b>Scoring Breakdown</b></summary>-->\n",
    "|Question| Manual | Points|\n",
    "|---|---|---|\n",
    "|Q1a | No | 2 |\n",
    "|Q1b | No | 2 |\n",
    "|Q2 | No | 3 |\n",
    "|Q3 | No | 3 |\n",
    "|Q4a | Yes | 1 |\n",
    "|Q4b | No | 1 |\n",
    "|Q4c | No | 1 |\n",
    "|Q4d | No | 1 |\n",
    "|Q4e | No | 2 |\n",
    "|Q5a | Yes | 2 |\n",
    "|Q5b | Yes | 2 |\n",
    "|Q6 | Yes | 2 |\n",
    "|Total | 4 | 22 |\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b2fef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to set up your notebook.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import sqlalchemy\n",
    "from pathlib import Path\n",
    "\n",
    "plt.style.use('fivethirtyeight') # Use plt.style.available to see more styles\n",
    "sns.set()\n",
    "sns.set_context(\"talk\")\n",
    "np.set_printoptions(threshold=5) # Avoid printing out big matrices\n",
    "%matplotlib inline\n",
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dcdced",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br/><br/>\n",
    "\n",
    "---\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "---\n",
    "<a id='part-1'></a>\n",
    "## Part 1: The IMDB (mini) Dataset\n",
    "\n",
    "\n",
    "We will explore a miniature version of the [IMDb Dataset](https://www.imdb.com/interfaces/). This is the same dataset that we used for this week's lab. The remainder of this overview section is copied from this week's lab.\n",
    "\n",
    "A few reminders: \n",
    "* **Only SQL code written with `pd.read_sql` will be graded.**  You should feel free to create `%%sql` cells for debugging, but you will still need to copy over any SQL to the Python answer cells and delete these additional debugging cells before submission. \n",
    "\n",
    "* **Caution: Be careful with large SQL queries!!** You may need to reboot your Jupyter Hub instance if it stops responding. To avoid printing out 100k-sized tables, **use the LIMIT keyword** (but remember to remove it).\n",
    "\n",
    "Let's load in the database in two ways (using both Python and cell magic) so that we can flexibly explore the SQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d954a524",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import pathlib\n",
    "\n",
    "# Do not modify following lines.\n",
    "\n",
    "# These lines specify the location of our database file\n",
    "dbfile = 'imdbmini.db'\n",
    "tmpdb = Path('data') / dbfile\n",
    "\n",
    "# Specify the database connection path (in this case, a sqlite database in a file)\n",
    "sqlite_conn = 'sqlite:///' + str(tmpdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44f3f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to connect to database\n",
    "engine = sqlalchemy.create_engine(sqlite_conn)\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa1cf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299471b1",
   "metadata": {},
   "source": [
    "Let's take a look at the table schemas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413681d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- just run this cell --\n",
    "SELECT * FROM sqlite_master WHERE type='table';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4089a750",
   "metadata": {},
   "source": [
    "From running the above cell, we see the database has 4 tables: `Name`, `Role`, `Rating`, and `Title`.\n",
    "\n",
    "<details open>\n",
    "    <summary>[<b>Click to Expand</b>] See descriptions of each table's schema.</summary>\n",
    "    \n",
    "**`Name`** – Contains the following information for names of people.\n",
    "    \n",
    "- nconst (integer) - alphanumeric unique identifier of the name/person\n",
    "- primaryName (text)– name by which the person is most often credited\n",
    "- birthYear (text) – in YYYY format\n",
    "- deathYear (text) – in YYYY format\n",
    "    \n",
    "    \n",
    "**`Role`** – Contains the principal cast/crew for titles.\n",
    "    \n",
    "- tconst (integer) - alphanumeric unique identifier of the title\n",
    "- ordering (text) – a number to uniquely identify rows for a given tconst\n",
    "- nconst (integer) - alphanumeric unique identifier of the name/person\n",
    "- category (text) - the category of job that person was in\n",
    "- characters (text) - the name of the character played if applicable, else '\\\\N'\n",
    "    \n",
    "**`Rating`** – Contains the IMDb rating and votes information for titles.\n",
    "    \n",
    "- tconst (integer) - alphanumeric unique identifier of the title\n",
    "- averageRating (text) – weighted average of all the individual user ratings\n",
    "- numVotes (text) - number of votes (i.e., ratings) the title has received\n",
    "    \n",
    "**`Title`** - Contains the following information for titles.\n",
    "    \n",
    "- tconst (integer) - alphanumeric unique identifier of the title\n",
    "- titleType (text) -  the type/format of the title\n",
    "- primaryTitle (text) -  the more popular title / the title used by the producers on promotional materials at the point of release\n",
    "- isAdult (text) - 0: non-adult title; 1: adult title\n",
    "- startYear (text) – represents the release year of a title.\n",
    "- runtimeMinutes (text)  – primary runtime of the title, in minutes\n",
    "    \n",
    "</details>\n",
    "\n",
    "<br/><br/>\n",
    "From the above descriptions, we can conclude the following:\n",
    "* `Name.nconst` and `Title.tconst` are primary keys of the `Name` and `Title` tables, respectively.\n",
    "* `Role.nconst` and `Role.tconst` are **foreign keys** that point to `Name.nconst` and `Title.tconst`, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f819e7ca",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 1a\n",
    "How far back does our data go? Does it only include recent data, or do we have information about older movies and movie stars as well? \n",
    "\n",
    "List the **10 oldest movie titles** (we define a movie as having `titleType=’movie’`) by `startYear` and then `primaryTitle` both in **ascending** order. The output should contain the `startYear`, `primaryTitle`, and `titleType`.\n",
    "\n",
    "Remember, you can create a `%%sql` cell **after** the grader cell as scratch work. Just be sure to copy the query back into the Python cell to run the autograder and delete them before submitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7220b3c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_q1a = \"\"\"\n",
    "...       # replace this with\n",
    "...;      # your multi-line solution\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "res_q1a = pd.read_sql(query_q1a, engine)\n",
    "res_q1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc54a90d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e248ec73",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 1b\n",
    "\n",
    "Next, let's calculate the distribution of movies by year. Write a query that returns the **total** number of movie titles for each `startYear` in the `Title` table as `total`.  Keep in mind that some entries may not have a `startYear` listed -- you should filter those out.  Order your final results by the `startYear` in **ascending** order. As in the `q1a`, remember that movies are defined as having `titleType=’movie’`.\n",
    "\n",
    "The first few records of the table should look like the following (but you should compute the entire table).\n",
    "\n",
    "\n",
    "| |startYear|total|\n",
    "|-----|------|-----|\n",
    "|**0**|1915|1|\n",
    "|**1**|1920|1|\n",
    "|**2**|1921|1|\n",
    "|**3**|1922|1|\n",
    "|...|...|...|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92255849",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_q1b = \"\"\"\n",
    "...       # replace this with\n",
    "...;      # your multi-line solution\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "res_q1b = pd.read_sql(query_q1b, engine)\n",
    "res_q1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f443921",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b510131",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "The following cell should generate an interesting plot of the number of movies that premiered each year. Notice there are less movies premiering from the 1920s to late 1940s. Why might that be? *This question is rhetorical; you do not need to write your answer anywhere.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7c57f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this call to generate the bar plot.\n",
    "px.bar(res_q1b, x=\"startYear\", y=\"total\", title=\"Number of movies premiered each year\", width=1000, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022d6c2b",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 2\n",
    "\n",
    "Who are the **top 10 most prolific movie actors**?\n",
    "\n",
    "Define the term **\"movie actor\"** is defined as anyone with an `\"actor\"` or `\"actress\"` job category role in a `\"movie\"` title type.\n",
    "\n",
    "Your SQL query should output exactly two fields named `name` (the movie actor name) and `total` (the number of movies the movie actor appears in). Order the records by `total` in descending order, and break ties by ordering by `name` in ascending order.\n",
    "\n",
    "Your result should look something like the following, but without `????`:\n",
    "\n",
    "| | name | total |\n",
    "|-----|-----|-----|\n",
    "|**0**| ???? | 64 |\n",
    "|**1**| ???? | 54 |\n",
    "|**2**| ???? | 53 |\n",
    "|**3**| ???? | 49 |\n",
    "|**4**| ???? | 46 |\n",
    "|**5**| ???? | 43 |\n",
    "|**6**| ???? | 41 |\n",
    "|**7**| ???? | 40 |\n",
    "|**8**| ???? | 40 |\n",
    "|**9**| ???? | 39 |\n",
    "\n",
    "**Hints**:\n",
    "\n",
    "* ***The query should take < 2 minutes to run.***\n",
    "* Before writing your query, you may wish to review the table descriptions given at the start of the assignment to determine where the information you need is stored\n",
    "* If you want to include a non-aggregate field in the `SELECT` clause, it must also be included in the `GROUP BY` clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbf3a0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_q2 = \"\"\"\n",
    "...       # replace this with\n",
    "...;      # your multi-line solution\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "res_q2 = pd.read_sql(query_q2, engine)\n",
    "res_q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329a937b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc694cf",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 3: The `CASE` Keyword\n",
    "\n",
    "The `Rating` table has the `numVotes` and the `averageRating` for each title. A movie is considered a **\"big hit**\" if there were more than 100,000 votes for the movie. Which `movie` titles were **\"big hits\"**? Construct a query that generates the following result:\n",
    "\n",
    "| | isBigHit | total |\n",
    "|-----|-----|-----|\n",
    "|**0**| no | ???? |\n",
    "|**1**| yes | ???? |\n",
    "\n",
    "Where `????` is replaced with the correct values. The row with `no` should have the count for how many movies **are not** big hits, and the row with `yes` should have the count of how many movies **are** big hits.\n",
    "\n",
    "**Hints**:\n",
    "\n",
    "* While SQL sometimes casts data automatically, it is still best practice to cast string data to a numerical data type manually before performing arithmetic operations for the purposes of readability and reproducibility.\n",
    "* You will need to use some type of `JOIN`.\n",
    "* You may also consider using a `CASE` statement:\n",
    "    ```\n",
    "    CASE \n",
    "        WHEN ... THEN ...\n",
    "        ELSE ... \n",
    "    END\n",
    "    ```\n",
    " `CASE` statements are the SQL-equivalent of Python `if... elif... else` statements. To read up on `CASE`, take a look at the following links:\n",
    "    - https://mode.com/sql-tutorial/sql-case/\n",
    "    - https://www.w3schools.com/sql/sql_ref_case.asp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b63d0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_q3 = \"\"\"\n",
    "...       # replace this with\n",
    "...;      # your multi-line solution\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "res_q3 = pd.read_sql(query_q3, engine)\n",
    "res_q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c16ccd8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c29c03",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "---\n",
    "\n",
    "<a id='part-2'></a>\n",
    "# Part 2: U.S. Presidential Elections By State\n",
    "\n",
    "(Click [here](#top) to jump back to the top of this notebook.)\n",
    "\n",
    "The second part of this homework focuses on a new dataset. If you haven't worked with Principal Component Analysis before, we highly encourage you to take a look at the PCA lab first. PCA really shines on data where you have reason to believe that the data is relatively low in rank. \n",
    "\n",
    "We'll look at how states voted in presidential elections between 1972 and 2016. **Our ultimate goal in this part is to show how 2D PCA scatterplots can allow us to identify clusters in a high dimensional dataset.** For this example, that means finding groups of states that vote similarly by plotting their 1st and 2nd principal components.\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 4\n",
    "\n",
    "We explore a dataset on U.S. Presidential Elections by State since 1789, as taken from [Wikipedia](https://en.wikipedia.org/wiki/List_of_United_States_presidential_election_results_by_state)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ff9b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/presidential_elections.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa552600",
   "metadata": {},
   "source": [
    "The data in this table is pretty messy (missing records, inconsistent field naming, etc.), so let's create a clean version.\n",
    "\n",
    "Running the cell below will produce a clean table, which contains exactly 51 rows (corresponding to the 50 states plus Washington DC) and 13 columns (one for each of the election years from 1972 to 2020). The index of this dataframe is the state name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a20872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "df_clean = ( \n",
    "        df.iloc[:, -15:]    \n",
    "        .drop(['Unnamed: 60'], axis = 1) \n",
    "        .rename(columns = {\"2000 ‡\": \"2000\", \"2016 ‡\": \"2016\", \"State.1\": \"State\"}) \n",
    "        .drop([51]) \n",
    "        .set_index(\"State\")\n",
    ")\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcb9eaa",
   "metadata": {},
   "source": [
    "Side note: We produced the data cleaning function chain above by inspecting the CSV file. In your personal projects, you may be tempted to use Excel or Google Sheets (What You See Is What You Get, or WYSIWYG) to clean data. While sometimes more convenient, the downside of this is that you have no record of what you did—and if you have to redownload the data, you have to redo the manual data cleaning process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39826e22",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "### Question 4a\n",
    "\n",
    "What does each row in `df_clean` represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56193cf9",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fec6257",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "### Question 4b\n",
    "\n",
    "Our dataset has 13 features in it, which are difficult to interpret all at once (in particular, we certainly can’t create a plot that can visualize all 13 dimensions at once). To better understand the major patterns in our data, we will **reduce its dimensionality** by applying PCA. Specifically, we’ll reduce the data from 13 features down to just 2 principal components.\n",
    "\n",
    "To perform PCA, we need to convert our data into numerical values. Create a `df_numerical` dataframe that replaces all of the \"D\" characters in `df_clean` with the number 0, and all of the \"R\" characters with the number 1. \n",
    "\n",
    "**Hint:** Use `df.replace` ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36e8619",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_numerical = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27755f79",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21c4e7a",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "### Question 4c\n",
    "\n",
    "Now **standardize the data**: Center the data so that each column's mean is 0, and scale the data so that each column's variance is 1. Store your result in `df_standardized`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70e7dd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_standardized = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d968c1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef9d918",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "We now have our data in a nice and tidy centered and scaled format. Phew! We are now ready to do PCA.\n",
    "\n",
    "<br/>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "### Question 4d: SVD\n",
    "\n",
    "In the following cell, compute the SVD of `df_standardized`:\n",
    "\n",
    "$$\\texttt{df}\\_\\texttt{standardized}=U\\Sigma V^{T}$$\n",
    "\n",
    "\n",
    "Store the $U$, $\\Sigma$, and $V^T$ matrices in `u`, `s`, and `vt` respectively. This is one line of simple code (exactly like what we saw in lecture and what you did in lab) using the [`np.linalg.svd`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.svd.html) function with the `full_matrices` argument set to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52ad376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "u, s, vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaf167c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcfc9e0",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "### Question 4e: Get Principal Components\n",
    "\n",
    "Using your results from the previous part, create a new `first_2_pcs` **dataframe** ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html)) that contains exactly the first two columns of the principal components matrix. The first column should be labeled `pc1` and the second column should be labeled `pc2`. Store your result in `first_2_pcs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8038f9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "first_2_pcs = ...\n",
    "first_2_pcs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96631385",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63160ac",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 5\n",
    "\n",
    "The cell below plots the 1st and 2nd principal components of our 50 states + Washington DC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a75369",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "sns.scatterplot(data = first_2_pcs, x = \"pc1\", y = \"pc2\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6578b3",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Unfortunately, we have two problems:\n",
    "\n",
    "1. There is a lot of overplotting, with only 28 distinct dots (out of 51 points). This means that at least some states voted exactly alike in these elections.\n",
    "2. We don't know which state is which because the points are unlabeled.\n",
    "\n",
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "### Question 5a: Jitter\n",
    "\n",
    "Let's start by addressing problem 1. \n",
    "\n",
    "**In the cell below, create a new dataframe `first_2_pcs_jittered` with a small amount of random noise added to each principal component. In this same cell, create a scatterplot.**\n",
    "\n",
    "To reduce overplotting, we **jitter** the first two principal components (a concept we first discussed in [Lecture 7](https://ds100.org/su23/lecture/lec07/)):\n",
    "* Add a small amount of random, unbiased Gaussian noise to each value using `np.random.normal` ([documentation](https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html)) with mean 0 and standard deviation less than 1.\n",
    "* Don't get caught up on the exact details of your noise generation; it's fine as long as your plot looks roughly the same as the original scatterplot, but without overplotting.\n",
    "* The amount of noise you add *should not significantly affect* the appearance of the plot; it should simply serve to separate overlapping observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c074322",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# first, jitter the data\n",
    "first_2_pcs_jittered = ...\n",
    "\n",
    "# then, create a scatter plot\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2d0ac7",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "### Question 5b\n",
    "\n",
    "To address Problem 2, we can turn to Plotly. The below cell uses these Plotly guides ([example 1](https://plot.ly/python/text-and-annotations/), [example 2](https://plotly.com/python/hover-text-and-formatting/#disabling-or-customizing-hover-of-columns-in-plotly-express)) to create a scatter plot of the jittered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44c3f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "import plotly.express as px\n",
    "\n",
    "# get the state names from the standardized dataframe's index\n",
    "first_2_pcs_jittered['state'] = df_standardized.index\n",
    "\n",
    "# show state names on hover\n",
    "fig = px.scatter(first_2_pcs_jittered, x=\"pc1\", y=\"pc2\",\n",
    "                hover_data={\"state\": True}, width=800, height=400); \n",
    "\n",
    "fig.show(); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8954d1",
   "metadata": {},
   "source": [
    "Analyze the above plot. In the below cell, address the following two points:\n",
    "1. Give an example of a cluster of states that vote a similar way. Does the composition of this cluster surprise you? If you're not familiar with U.S. politics, it's fine to just say \"No, I'm not surprised because I don't know anything about U.S. politics.\"\n",
    "1. Include anything interesting that you observe. You will get credit for this as long as you write something reasonable that you can takeaway from the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28953a93",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328c548d",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 6\n",
    "\n",
    "We can also look at the contributions of each year's elections results on the values for our principal components.\n",
    "\n",
    "Below, we define the `plot_pc` function that plots and labels the rows of $V^T$. We then call this function to plot the 1st row of $V^T$, i.e., the row of $V^T$ that corresponds to `pc1`.\n",
    "\n",
    "**Note**: If you get an error when running this cell, make sure you are properly assigning the `vt` variable from Question 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b676f884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "\n",
    "def plot_pc(col_names, row_mat_vt, k):\n",
    "    plt.bar(col_names, row_mat_vt[k, :], alpha=0.7)\n",
    "    plt.xticks(col_names, rotation=90);\n",
    "    \n",
    "plt.figure(figsize=(12, 4)) # adjusts size of plot\n",
    "plot_pc(list(df_standardized.columns), vt, 0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b048f0",
   "metadata": {},
   "source": [
    "To get a better sense of whether our 2D scatterplot captures the whole story, create a **scree plot** for this data. In other words, plot the variance (y-axis) captured by the ith principal component (x-axis), as we did in [Lab 12](http://data100-jl4.datahub.berkeley.edu/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2FDS-100%2Fsu23-materials&branch=main&urlpath=lab%2Ftree%2Fsu23-materials%2Flab%2Flab12%2Flab12.ipynb).\n",
    "\n",
    "**Hint:** Be sure to label your axes appropriately! You may find `plt.xticks()` ([documentation](https://matplotlib.org/3.5.0/api/_as_gen/matplotlib.pyplot.xticks.html)) helpful for formatting. Also check out the lab for more on scree plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6ae4a4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4138f6",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/>\n",
    "\n",
    "From your scree plot above, you should see that the first two principal components capture a large portion of the variance in our cleaned data. It is partially for this reason that the 2D scatter plot of principal components was easy to interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebc4dd0",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "finish",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "tags": []
   },
   "source": [
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "\n",
    "## Congratulations! You finished Homework 8!\n",
    "\n",
    "Below, you will see two cells. Running the first cell will automatically generate a PDF of all questions that need to be manually graded, and running the second cell will automatically generate a zip with your autograded answers. **You are responsible for both the coding portion (the zip from Homework 8) and the written portion (the PDF with from Homework 8) to their respective Gradescope portals.** The coding proportion should be submitted to Homework 8 Coding as a single zip file, and the written portion should be submitted to Homework 8 Written as a single pdf file. When submitting the written portion, please ensure you select pages appropriately and check all plots appear. \n",
    "\n",
    "If there are issues with automatically generating the PDF in the first cell, you can try downloading the notebook as a PDF by clicking on `File -> Save and Export Notebook As... -> PDF`. If that doesn't work either, you can manually take screenshots of your answers to the manually graded questions and submit those. Either way, **you are responsible for ensuring your submission follows our requirements, we will NOT be granting regrade requests for submissions that don't follow instructions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f8ce9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from otter.export import export_notebook\n",
    "from os import path\n",
    "from IPython.display import display, HTML\n",
    "export_notebook(\"hw08.ipynb\", filtering=True, pagebreaks=True)\n",
    "if(path.exists('hw08.pdf')):\n",
    "    display(HTML(\"Download your PDF <a href='hw08.pdf' download>here</a>.\"))\n",
    "else:\n",
    "    print(\"\\n Pdf generation fails, please try the other methods described above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c354571",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96893a21",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ed3387",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1a": {
     "name": "q1a",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> res_q1a.shape == (10, 3)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(res_q1a.columns) == set(['startYear', 'primaryTitle', 'titleType'])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.all(res_q1a[\"titleType\"] == \"movie\")\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1b": {
     "name": "q1b",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> res_q1b.shape == (102, 2)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> res_q2.shape == (10, 2)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(res_q2.columns) == set(['name', 'total'])\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> res_q3.shape == (2, 2)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(res_q3.columns) == set(['isBigHit', 'total'])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(res_q3['isBigHit']) == set(['yes', 'no'])\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4b": {
     "name": "q4b",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # TEST\n>>> np.all(df_numerical.applymap(lambda x: x in [0, 1]))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # TEST\n>>> df_numerical['1972']['Alabama'] == 1\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4c": {
     "name": "q4c",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # TEST\n>>> all(np.isclose(np.mean(df_standardized), [0] * df_standardized.shape[1]))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # TEST\n>>> all(np.isclose(np.var(df_standardized), [1] * df_standardized.shape[1]))\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4d": {
     "name": "q4d",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # TEST\n>>> all(np.isclose([sum(u[:, i] ** 2) for i in range(u.shape[1])], np.ones((u.shape[1],))))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # TEST\n>>> all(np.isclose([sum(vt[i, :] ** 2) for i in range(vt.shape[1])], np.ones((u.shape[1],))))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # TEST\n>>> len(s) == 13\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # TEST\n>>> (np.isclose(u @ np.diag(s) @ vt, df_standardized)).all()\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4e": {
     "name": "q4e",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # TEST\n>>> first_2_pcs.shape == (51, 2)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # TEST\n>>> all(first_2_pcs.columns == ['pc1', 'pc2'])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # TEST\n>>> all(np.isclose(first_2_pcs.loc[0], [-2.9386, 0.7964], atol=1e-4))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # TEST\n>>> all(np.isclose(first_2_pcs.loc[46], [-0.2960, -1.5452], atol=1e-4))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # TEST\n>>> all(np.isclose(first_2_pcs.loc[28], [0.9442, -1.5338], atol=1e-4))\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
